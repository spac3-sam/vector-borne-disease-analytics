{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_hdf('3B-MO.MS.MRG.3IMERG.20190801-S000000-E235959.08.V06B.HDF5')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Dataset(s) incompatible with Pandas data types, not table, or no datasets found in HDF5 file.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b2526529b61b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'3B-MO.MS.MRG.3IMERG.20190801-S000000-E235959.08.V06B.HDF5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\conda\\envs\\promed2021\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[1;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    409\u001b[0m                     \u001b[1;34m\"Dataset(s) incompatible with Pandas data types, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                     \u001b[1;34m\"not table, or no datasets found in HDF5 file.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dataset(s) incompatible with Pandas data types, not table, or no datasets found in HDF5 file."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import h5py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "f = h5py.File('3B-MO.MS.MRG.3IMERG.20190801-S000000-E235959.08.V06B.HDF5', 'r')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "f"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<HDF5 file \"3B-MO.MS.MRG.3IMERG.20190801-S000000-E235959.08.V06B.HDF5\" (mode r)>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "f.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['Grid']>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "f['Grid'].keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['nv', 'lonv', 'latv', 'time', 'lon', 'lat', 'time_bnds', 'lon_bnds', 'lat_bnds', 'precipitation', 'randomError', 'gaugeRelativeWeighting', 'probabilityLiquidPrecipitation', 'precipitationQualityIndex']>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "grid = f['Grid']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(\"Longitude data: {}\".format(grid['lon']))\r\n",
    "print(\"Longitude data attributes: {}\".format(list(grid['lon'].attrs)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Longitude data: <HDF5 dataset \"lon\": shape (3600,), type \"<f4\">\n",
      "Longitude data attributes: ['DimensionNames', 'Units', 'units', 'standard_name', 'LongName', 'bounds', 'axis', 'CLASS', 'REFERENCE_LIST']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(\"Name: {}\".format(grid['lon'].attrs['standard_name'].decode()))\r\n",
    "print(\"Unit: {}\".format(grid['lon'].attrs['units'].decode()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Name: longitude\n",
      "Unit: degrees_east\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "longitude_values = np.repeat(list(grid['lon']), 1800)\r\n",
    "latitude_values = list(grid['lat'])*3600\r\n",
    "precipitation_values = np.array(list(grid['precipitation'])).flatten()\r\n",
    "\r\n",
    "dataset = pd.DataFrame({\"lon\": longitude_values, \"lat\": latitude_values, \"precipitation\": precipitation_values})\r\n",
    "dataset.columns = [grid['lon'].attrs['standard_name'].decode() + \" (\" + grid['lon'].attrs['units'].decode() + \")\",\r\n",
    "                   grid['lat'].attrs['standard_name'].decode() + \" (\" + grid['lat'].attrs['units'].decode() + \")\",\r\n",
    "                   \"Precipitation (\" + grid['precipitation'].attrs['units'].decode() + \")\",]\r\n",
    "dataset.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   longitude (degrees_east)  latitude (degrees_north)  Precipitation (mm/hr)\n",
       "0               -179.949997                -89.949997           -9999.900391\n",
       "1               -179.949997                -89.849998           -9999.900391\n",
       "2               -179.949997                -89.750000           -9999.900391\n",
       "3               -179.949997                -89.650002           -9999.900391\n",
       "4               -179.949997                -89.550003           -9999.900391"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude (degrees_east)</th>\n",
       "      <th>latitude (degrees_north)</th>\n",
       "      <th>Precipitation (mm/hr)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-179.949997</td>\n",
       "      <td>-89.949997</td>\n",
       "      <td>-9999.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-179.949997</td>\n",
       "      <td>-89.849998</td>\n",
       "      <td>-9999.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-179.949997</td>\n",
       "      <td>-89.750000</td>\n",
       "      <td>-9999.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-179.949997</td>\n",
       "      <td>-89.650002</td>\n",
       "      <td>-9999.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-179.949997</td>\n",
       "      <td>-89.550003</td>\n",
       "      <td>-9999.900391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "dataset['Precipitation (mm/hr)'] = dataset['Precipitation (mm/hr)'].mask(\r\n",
    "                                    np.isclose(dataset['Precipitation (mm/hr)'], -9999.9), 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "dataset['Precipitation (mm/hr)'].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    6.480000e+06\n",
       "mean     9.321189e-02\n",
       "std      1.370286e-01\n",
       "min      0.000000e+00\n",
       "25%      3.924359e-04\n",
       "50%      4.468640e-02\n",
       "75%      1.331607e-01\n",
       "max      3.226260e+00\n",
       "Name: Precipitation (mm/hr), dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "source": [
    "import gc\r\n",
    "import pandas as pd\r\n",
    "import h5py\r\n",
    "from datetime import datetime\r\n",
    "import os\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "promed_df = pd.read_feather(r'F:\\OneDrive\\School\\research\\thilanka-summer2021\\scraper2.0\\combined_df_raw.feather')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataset = h5py.File('3B-MO.MS.MRG.3IMERG.20190801-S000000-E235959.08.V06B.HDF5', 'r')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from scipy.interpolate import RegularGridInterpolator\r\n",
    "\r\n",
    "itp = RegularGridInterpolator( (dataset['Grid']['lon'], dataset['Grid']['lat']), np.arange(3600*1800).reshape(3600,1800), method='nearest')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "def get_closest_gpm(data):\r\n",
    "\ttry:\r\n",
    "\t\tidx = int(itp((data.zoom_lon, data.zoom_lat)))\r\n",
    "\t\tlati = idx % 1800\r\n",
    "\t\tloni = idx // 1800\r\n",
    "\t\tdata['gpm_lat_idx'] = lati\r\n",
    "\t\tdata['gpm_lon_idx'] = loni\r\n",
    "\t\treturn data\r\n",
    "\texcept:\r\n",
    "\t\tdata['gpm_lat_idx'] = pd.NA\r\n",
    "\t\tdata['gpm_lon_idx'] = pd.NA\r\n",
    "\r\n",
    "promed_df[['zoom_lat', 'zoom_lon', 'gpm_lat_idx', 'gpm_lon_idx']] = promed_df[['zoom_lat', 'zoom_lon']].apply(get_closest_gpm, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "source": [
    "promed_df[['gpm_lat_idx', 'gpm_lon_idx']] = promed_df[['gpm_lat_idx', 'gpm_lon_idx']].fillna(-1).astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "source": [
    "promed_df.to_feather(r'F:\\OneDrive\\School\\research\\thilanka-summer2021\\scraper2.0\\combined_df_raw.feather')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "source": [
    "focus_points = pd.Series(list(zip(promed_df.gpm_lat_idx, promed_df.gpm_lon_idx))).unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "source": [
    "from collections import defaultdict\r\n",
    "from tqdm import tqdm\r\n",
    "precip_totals = defaultdict(lambda: 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "source": [
    "for dataset_path in tqdm([x for x in os.listdir() if x.endswith('.HDF5')]):\r\n",
    "\twith h5py.File(dataset_path, 'r') as dataset:\r\n",
    "\t\tfor lat, lon in focus_points:\r\n",
    "\t\t\tprecip_totals[(lat, lon)] += dataset['Grid']['precipitation'][0][lon][lat]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/250 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12952/3079059804.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlon\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfocus_points\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                         \u001b[0mprecip_totals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Grid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'precipitation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlon\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mF:\\conda\\envs\\geopandas\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, args, new_dtype)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[1;31m# Patch up the output for NumPy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "source": [
    "len([x for x in os.listdir() if x.endswith('.HDF5')])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "metadata": {},
     "execution_count": 222
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "output = pd.DataFrame([[key[0], key[1], value] for key, value in precip_totals.items()], columns=['lat_idx', 'lon_idx', 'total_precip'])\r\n",
    "output.to_csv('total_precip.csv')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0, 0)]"
      ]
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import fiona"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# import h5py\r\n",
    "import pandas as pd\r\n",
    "import geopandas\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import fiona"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "f = pd.read_hdf(r'F:\\research\\gpm_premise\\3B-MO.MS.MRG.3IMERG.20151201-S000000-E235959.12.V06B.HDF5')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'tables'.  Use pip or conda to install tables.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36024/165819389.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'F:\\research\\gpm_premise\\3B-MO.MS.MRG.3IMERG.20151201-S000000-E235959.12.V06B.HDF5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\conda\\envs\\geopandas\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[1;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"File {path_or_buf} does not exist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m         \u001b[0mstore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m         \u001b[1;31m# can't auto open/close if we are using an iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;31m# so delegate to the iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\conda\\envs\\geopandas\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"format is not a defined argument for HDFStore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mtables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tables\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomplib\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcomplib\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_complibs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\conda\\envs\\geopandas\\lib\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'tables'.  Use pip or conda to install tables."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "f = h5py.File(r'F:\\research\\gpm_premise\\3B-MO.MS.MRG.3IMERG.20151201-S000000-E235959.12.V06B.HDF5', 'r')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "precip = f['Grid/precipitation'][0][:][:]\r\n",
    "precip = np.transpose(precip)\r\n",
    "theLats = f['Grid/lat'][:]\r\n",
    "theLons = f['Grid/lon'][:]\r\n",
    "x, y = np.float32(np.meshgrid(theLons, theLats))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "fig = plt.figure(figsize=(21,7))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1512x504 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "ax.set_extent([-180,180,-60,60])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'ax' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16480/1605676066.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_extent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ax' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import geopandas"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "partially initialized module 'fiona' has no attribute '_loading' (most likely due to a circular import)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16480/1529612126.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\conda\\envs\\geopandas\\lib\\site-packages\\geopandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpoints_from_xy\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_read_file\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mread_file\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_read_parquet\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mread_parquet\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_read_feather\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mread_feather\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\conda\\envs\\geopandas\\lib\\site-packages\\geopandas\\io\\file.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mfiona\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mfiona_import_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\conda\\envs\\geopandas\\lib\\site-packages\\fiona\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiona\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mfiona\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_gdal_dll_directories\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBytesCollection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCollection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrvsupport\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msupported_drivers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'fiona' has no attribute '_loading' (most likely due to a circular import)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import pandas as pd\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "why = {\r\n",
    "'precip': np.array(f['Grid/precipitation']),\r\n",
    "'lat': np.array(f['Grid/lat'][:]),\r\n",
    "'lon': np.array(f['Grid/lon'][:])\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "with open('gpm.pickle', 'wb') as handle:\r\n",
    "\tpickle.dump(why, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "np.array(f['Grid/precipitation'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[-9999.9, -9999.9, -9999.9, ..., -9999.9, -9999.9, -9999.9],\n",
       "        [-9999.9, -9999.9, -9999.9, ..., -9999.9, -9999.9, -9999.9],\n",
       "        [-9999.9, -9999.9, -9999.9, ..., -9999.9, -9999.9, -9999.9],\n",
       "        ...,\n",
       "        [-9999.9, -9999.9, -9999.9, ..., -9999.9, -9999.9, -9999.9],\n",
       "        [-9999.9, -9999.9, -9999.9, ..., -9999.9, -9999.9, -9999.9],\n",
       "        [-9999.9, -9999.9, -9999.9, ..., -9999.9, -9999.9, -9999.9]]],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "np.array(f['Grid/lat'][:])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-89.95, -89.85, -89.75, ...,  89.75,  89.85,  89.95], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "np.array(f['Grid/lon'][:])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-179.95, -179.85, -179.75, ...,  179.75,  179.85,  179.95],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "f['Grid/precipitation'][0][:][:].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3600, 1800)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\r\n",
    "import h5py\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import cartopy.crs as ccrs\r\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\r\n",
    "import matplotlib.ticker as mticker\r\n",
    "\r\n",
    "# Open the IMERG data file; it may be necessary to add a path if the file is not in the working directory.\r\n",
    "\r\n",
    "\r\n",
    "f = h5py.File(r'F:\\research\\gpm_premise\\3B-MO.MS.MRG.3IMERG.20010301-S000000-E235959.03.V06B.HDF5', 'r')\r\n",
    "\r\n",
    "# View the available groups in the file and the variables in the 'Grid' group:\r\n",
    "\r\n",
    "groups = [ x for x in f.keys() ]\r\n",
    "print(groups)\r\n",
    "gridMembers = [ x for x in f['Grid'] ]\r\n",
    "print(gridMembers)\r\n",
    "\r\n",
    "# Read the precipitation, latitude, and longitude data:\r\n",
    "\r\n",
    "precip = f['Grid/precipitation'][0][:][:]\r\n",
    "precip = np.transpose(precip)\r\n",
    "theLats = f['Grid/lat'][:]\r\n",
    "theLons = f['Grid/lon'][:]\r\n",
    "x, y = np.float32(np.meshgrid(theLons, theLats))\r\n",
    " \r\n",
    "\r\n",
    "# Plot the data using matplotlib and cartopy\r\n",
    "\r\n",
    "# Set the figure size, projection, and extent\r\n",
    "fig = plt.figure(figsize=(21,7))\r\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\r\n",
    "# ax.set_extent([-180,180,-60,60])  \r\n",
    "\r\n",
    "# Add coastlines and formatted gridlines\r\n",
    "ax.coastlines(resolution=\"110m\",linewidth=1)\r\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\r\n",
    "                  linewidth=1, color='black', linestyle='--')\r\n",
    "gl.xlabels_top = False\r\n",
    "gl.ylabels_right = False\r\n",
    "gl.xlines = True\r\n",
    "gl.xlocator = mticker.FixedLocator([-180, -90, 0, 90, 180])\r\n",
    "gl.ylocator = mticker.FixedLocator([-60, -50, -25, 0, 25, 50, 60])\r\n",
    "gl.xformatter = LONGITUDE_FORMATTER\r\n",
    "gl.yformatter = LATITUDE_FORMATTER\r\n",
    "gl.xlabel_style = {'size':16, 'color':'black'}\r\n",
    "gl.ylabel_style = {'size':16, 'color':'black'}\r\n",
    "\r\n",
    "# Set contour levels and draw the plot\r\n",
    "clevs = np.arange(0,1.26,0.05)\r\n",
    "plt.contourf(x, y, precip, clevs, cmap=plt.cm.rainbow)\r\n",
    "plt.title('GPM IMERG Monthly Mean Rain Rate for January 2014', size=24)\r\n",
    "cb = plt.colorbar(ax=ax, orientation=\"vertical\", pad=0.02, aspect=16, shrink=0.8)\r\n",
    "cb.set_label('mm / hr',size=20)\r\n",
    "cb.ax.tick_params(labelsize=16)\r\n",
    "\r\n",
    "# Save the figure as a PNG:\r\n",
    "\r\n",
    "fig.savefig('GPM_3IMERGP_plot.png', bbox_inches='tight', pad_inches = 0.1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Grid']\n",
      "['nv', 'lonv', 'latv', 'time', 'lon', 'lat', 'time_bnds', 'lon_bnds', 'lat_bnds', 'precipitation', 'randomError', 'gaugeRelativeWeighting', 'probabilityLiquidPrecipitation', 'precipitationQualityIndex']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('geopandas': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "3387528f949e08a7465409a492fe128ebdb03217a22eb98a1ae9d56d862b3753"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}