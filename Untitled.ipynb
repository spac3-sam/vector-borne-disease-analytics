{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_hdf('3B-MO.MS.MRG.3IMERG.20190801-S000000-E235959.08.V06B.HDF5')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Dataset(s) incompatible with Pandas data types, not table, or no datasets found in HDF5 file.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b2526529b61b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'3B-MO.MS.MRG.3IMERG.20190801-S000000-E235959.08.V06B.HDF5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\conda\\envs\\promed2021\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[1;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    409\u001b[0m                     \u001b[1;34m\"Dataset(s) incompatible with Pandas data types, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                     \u001b[1;34m\"not table, or no datasets found in HDF5 file.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dataset(s) incompatible with Pandas data types, not table, or no datasets found in HDF5 file."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import h5py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "f = h5py.File('3B-MO.MS.MRG.3IMERG.20190801-S000000-E235959.08.V06B.HDF5', 'r')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "f"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<HDF5 file \"3B-MO.MS.MRG.3IMERG.20190801-S000000-E235959.08.V06B.HDF5\" (mode r)>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "f.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['Grid']>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "f['Grid'].keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['nv', 'lonv', 'latv', 'time', 'lon', 'lat', 'time_bnds', 'lon_bnds', 'lat_bnds', 'precipitation', 'randomError', 'gaugeRelativeWeighting', 'probabilityLiquidPrecipitation', 'precipitationQualityIndex']>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "grid = f['Grid']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(\"Longitude data: {}\".format(grid['lon']))\r\n",
    "print(\"Longitude data attributes: {}\".format(list(grid['lon'].attrs)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Longitude data: <HDF5 dataset \"lon\": shape (3600,), type \"<f4\">\n",
      "Longitude data attributes: ['DimensionNames', 'Units', 'units', 'standard_name', 'LongName', 'bounds', 'axis', 'CLASS', 'REFERENCE_LIST']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(\"Name: {}\".format(grid['lon'].attrs['standard_name'].decode()))\r\n",
    "print(\"Unit: {}\".format(grid['lon'].attrs['units'].decode()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Name: longitude\n",
      "Unit: degrees_east\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "longitude_values = np.repeat(list(grid['lon']), 1800)\r\n",
    "latitude_values = list(grid['lat'])*3600\r\n",
    "precipitation_values = np.array(list(grid['precipitation'])).flatten()\r\n",
    "\r\n",
    "dataset = pd.DataFrame({\"lon\": longitude_values, \"lat\": latitude_values, \"precipitation\": precipitation_values})\r\n",
    "dataset.columns = [grid['lon'].attrs['standard_name'].decode() + \" (\" + grid['lon'].attrs['units'].decode() + \")\",\r\n",
    "                   grid['lat'].attrs['standard_name'].decode() + \" (\" + grid['lat'].attrs['units'].decode() + \")\",\r\n",
    "                   \"Precipitation (\" + grid['precipitation'].attrs['units'].decode() + \")\",]\r\n",
    "dataset.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   longitude (degrees_east)  latitude (degrees_north)  Precipitation (mm/hr)\n",
       "0               -179.949997                -89.949997           -9999.900391\n",
       "1               -179.949997                -89.849998           -9999.900391\n",
       "2               -179.949997                -89.750000           -9999.900391\n",
       "3               -179.949997                -89.650002           -9999.900391\n",
       "4               -179.949997                -89.550003           -9999.900391"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude (degrees_east)</th>\n",
       "      <th>latitude (degrees_north)</th>\n",
       "      <th>Precipitation (mm/hr)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-179.949997</td>\n",
       "      <td>-89.949997</td>\n",
       "      <td>-9999.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-179.949997</td>\n",
       "      <td>-89.849998</td>\n",
       "      <td>-9999.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-179.949997</td>\n",
       "      <td>-89.750000</td>\n",
       "      <td>-9999.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-179.949997</td>\n",
       "      <td>-89.650002</td>\n",
       "      <td>-9999.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-179.949997</td>\n",
       "      <td>-89.550003</td>\n",
       "      <td>-9999.900391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "dataset['Precipitation (mm/hr)'] = dataset['Precipitation (mm/hr)'].mask(\r\n",
    "                                    np.isclose(dataset['Precipitation (mm/hr)'], -9999.9), 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "dataset['Precipitation (mm/hr)'].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    6.480000e+06\n",
       "mean     9.321189e-02\n",
       "std      1.370286e-01\n",
       "min      0.000000e+00\n",
       "25%      3.924359e-04\n",
       "50%      4.468640e-02\n",
       "75%      1.331607e-01\n",
       "max      3.226260e+00\n",
       "Name: Precipitation (mm/hr), dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "source": [
    "import gc\r\n",
    "import pandas as pd\r\n",
    "import h5py\r\n",
    "from datetime import datetime\r\n",
    "import os\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "promed_df = pd.read_feather(r'F:\\OneDrive\\School\\research\\thilanka-summer2021\\scraper2.0\\combined_df_raw.feather')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataset = h5py.File('3B-MO.MS.MRG.3IMERG.20190801-S000000-E235959.08.V06B.HDF5', 'r')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from scipy.interpolate import RegularGridInterpolator\r\n",
    "\r\n",
    "itp = RegularGridInterpolator( (dataset['Grid']['lon'], dataset['Grid']['lat']), np.arange(3600*1800).reshape(3600,1800), method='nearest')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "def get_closest_gpm(data):\r\n",
    "\ttry:\r\n",
    "\t\tidx = int(itp((data.zoom_lon, data.zoom_lat)))\r\n",
    "\t\tlati = idx % 1800\r\n",
    "\t\tloni = idx // 1800\r\n",
    "\t\tdata['gpm_lat_idx'] = lati\r\n",
    "\t\tdata['gpm_lon_idx'] = loni\r\n",
    "\t\treturn data\r\n",
    "\texcept:\r\n",
    "\t\tdata['gpm_lat_idx'] = pd.NA\r\n",
    "\t\tdata['gpm_lon_idx'] = pd.NA\r\n",
    "\r\n",
    "promed_df[['zoom_lat', 'zoom_lon', 'gpm_lat_idx', 'gpm_lon_idx']] = promed_df[['zoom_lat', 'zoom_lon']].apply(get_closest_gpm, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "source": [
    "promed_df[['gpm_lat_idx', 'gpm_lon_idx']] = promed_df[['gpm_lat_idx', 'gpm_lon_idx']].fillna(-1).astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "source": [
    "promed_df.to_feather(r'F:\\OneDrive\\School\\research\\thilanka-summer2021\\scraper2.0\\combined_df_raw.feather')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "source": [
    "focus_points = pd.Series(list(zip(promed_df.gpm_lat_idx, promed_df.gpm_lon_idx))).unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "source": [
    "from collections import defaultdict\r\n",
    "from tqdm import tqdm\r\n",
    "precip_totals = defaultdict(lambda: 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "source": [
    "for dataset_path in tqdm([x for x in os.listdir() if x.endswith('.HDF5')]):\r\n",
    "\twith h5py.File(dataset_path, 'r') as dataset:\r\n",
    "\t\tfor lat, lon in focus_points:\r\n",
    "\t\t\tprecip_totals[(lat, lon)] += dataset['Grid']['precipitation'][0][lon][lat]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/250 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12952/3079059804.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlon\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfocus_points\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                         \u001b[0mprecip_totals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Grid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'precipitation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlon\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mF:\\conda\\envs\\geopandas\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, args, new_dtype)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[1;31m# Patch up the output for NumPy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "source": [
    "len([x for x in os.listdir() if x.endswith('.HDF5')])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "metadata": {},
     "execution_count": 222
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "output = pd.DataFrame([[key[0], key[1], value] for key, value in precip_totals.items()], columns=['lat_idx', 'lon_idx', 'total_precip'])\r\n",
    "output.to_csv('total_precip.csv')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0, 0)]"
      ]
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('geopandas': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "3387528f949e08a7465409a492fe128ebdb03217a22eb98a1ae9d56d862b3753"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}